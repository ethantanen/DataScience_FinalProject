{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the csv created earlier into a data frame and then calculate z-scores for every effect in order to make our logistic regression model accurate and understandable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21400</td>\n",
       "      <td>0.666</td>\n",
       "      <td>178242</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>-5.743</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>100.014</td>\n",
       "      <td>4</td>\n",
       "      <td>0.178</td>\n",
       "      <td>1</td>\n",
       "      <td>#Beautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.807</td>\n",
       "      <td>183750</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>-3.282</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>127.973</td>\n",
       "      <td>4</td>\n",
       "      <td>0.651</td>\n",
       "      <td>1</td>\n",
       "      <td>#SELFIE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00162</td>\n",
       "      <td>0.791</td>\n",
       "      <td>279507</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>-6.149</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>128.017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.393</td>\n",
       "      <td>1</td>\n",
       "      <td>#thatPOWER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.76300</td>\n",
       "      <td>0.707</td>\n",
       "      <td>275227</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>-3.979</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>89.094</td>\n",
       "      <td>4</td>\n",
       "      <td>0.501</td>\n",
       "      <td>1</td>\n",
       "      <td>0 To 100 / The Catch Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.57000</td>\n",
       "      <td>0.629</td>\n",
       "      <td>250173</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>-7.733</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>100.015</td>\n",
       "      <td>4</td>\n",
       "      <td>0.386</td>\n",
       "      <td>1</td>\n",
       "      <td>1-800-273-8255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n",
       "0       0.21400         0.666       178242   0.677          0.000000    2   \n",
       "1       0.01340         0.807       183750   0.916          0.000012    0   \n",
       "2       0.00162         0.791       279507   0.615          0.000065    6   \n",
       "3       0.76300         0.707       275227   0.709          0.000000   11   \n",
       "4       0.57000         0.629       250173   0.572          0.000000    5   \n",
       "\n",
       "   liveness  loudness  speechiness    tempo  time_signature  valence  label  \\\n",
       "0    0.0979    -5.743       0.0326  100.014               4    0.178      1   \n",
       "1    0.0787    -3.282       0.2260  127.973               4    0.651      1   \n",
       "2    0.0812    -6.149       0.0667  128.017               4    0.393      1   \n",
       "3    0.2740    -3.979       0.3400   89.094               4    0.501      1   \n",
       "4    0.1920    -7.733       0.0387  100.015               4    0.386      1   \n",
       "\n",
       "                     title  \n",
       "0               #Beautiful  \n",
       "1                  #SELFIE  \n",
       "2               #thatPOWER  \n",
       "3  0 To 100 / The Catch Up  \n",
       "4           1-800-273-8255  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../DataSets/balanced_pop_unpop_features.csv\", sep=\",\")\n",
    "data['title'] = data['Unnamed: 0']\n",
    "data = data.drop('Unnamed: 0', axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.234429</td>\n",
       "      <td>0.153280</td>\n",
       "      <td>-1.087287</td>\n",
       "      <td>-0.034082</td>\n",
       "      <td>-0.111864</td>\n",
       "      <td>-0.924928</td>\n",
       "      <td>-0.569818</td>\n",
       "      <td>0.078899</td>\n",
       "      <td>-0.665590</td>\n",
       "      <td>-0.776052</td>\n",
       "      <td>0.110072</td>\n",
       "      <td>-1.499069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.744047</td>\n",
       "      <td>1.169892</td>\n",
       "      <td>-0.953584</td>\n",
       "      <td>1.390222</td>\n",
       "      <td>-0.111643</td>\n",
       "      <td>-1.467484</td>\n",
       "      <td>-0.704061</td>\n",
       "      <td>1.114347</td>\n",
       "      <td>1.339700</td>\n",
       "      <td>0.212902</td>\n",
       "      <td>0.110072</td>\n",
       "      <td>0.635067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.801507</td>\n",
       "      <td>1.054532</td>\n",
       "      <td>1.370844</td>\n",
       "      <td>-0.403567</td>\n",
       "      <td>-0.110689</td>\n",
       "      <td>0.160186</td>\n",
       "      <td>-0.686582</td>\n",
       "      <td>-0.091923</td>\n",
       "      <td>-0.312020</td>\n",
       "      <td>0.214459</td>\n",
       "      <td>0.110072</td>\n",
       "      <td>-0.529007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.912313</td>\n",
       "      <td>0.448891</td>\n",
       "      <td>1.266950</td>\n",
       "      <td>0.156620</td>\n",
       "      <td>-0.111864</td>\n",
       "      <td>1.516578</td>\n",
       "      <td>0.661443</td>\n",
       "      <td>0.821089</td>\n",
       "      <td>2.521722</td>\n",
       "      <td>-1.162309</td>\n",
       "      <td>0.110072</td>\n",
       "      <td>-0.041720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.970908</td>\n",
       "      <td>-0.113491</td>\n",
       "      <td>0.658783</td>\n",
       "      <td>-0.659823</td>\n",
       "      <td>-0.111864</td>\n",
       "      <td>-0.111093</td>\n",
       "      <td>0.088113</td>\n",
       "      <td>-0.758380</td>\n",
       "      <td>-0.602341</td>\n",
       "      <td>-0.776016</td>\n",
       "      <td>0.110072</td>\n",
       "      <td>-0.560590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms    energy  instrumentalness  \\\n",
       "0      0.234429      0.153280    -1.087287 -0.034082         -0.111864   \n",
       "1     -0.744047      1.169892    -0.953584  1.390222         -0.111643   \n",
       "2     -0.801507      1.054532     1.370844 -0.403567         -0.110689   \n",
       "3      2.912313      0.448891     1.266950  0.156620         -0.111864   \n",
       "4      1.970908     -0.113491     0.658783 -0.659823         -0.111864   \n",
       "\n",
       "        key  liveness  loudness  speechiness     tempo  time_signature  \\\n",
       "0 -0.924928 -0.569818  0.078899    -0.665590 -0.776052        0.110072   \n",
       "1 -1.467484 -0.704061  1.114347     1.339700  0.212902        0.110072   \n",
       "2  0.160186 -0.686582 -0.091923    -0.312020  0.214459        0.110072   \n",
       "3  1.516578  0.661443  0.821089     2.521722 -1.162309        0.110072   \n",
       "4 -0.111093  0.088113 -0.758380    -0.602341 -0.776016        0.110072   \n",
       "\n",
       "    valence  \n",
       "0 -1.499069  \n",
       "1  0.635067  \n",
       "2 -0.529007  \n",
       "3 -0.041720  \n",
       "4 -0.560590  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_title = data.drop(['title', 'label'], axis=1)\n",
    "z_scores=(no_title - no_title.mean())/no_title.std()\n",
    "z_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test a few different combinations of effects in order to find a model with the most predictive power. We first run a logistic regression using all of the features, then we chose the three features with the highest impact on the logistic regression that included all features and re-run a regression using only those 3. \n",
    "\n",
    "We also test our initial hypothesis that danceability alone will be a good predictor of popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to create another version of this model we calculated the total correlation between all variables and all other variables in order to try and determine which features could be excluded from the next iteration of the model. This lead us to using key, instrumentalness, and duration as the paramaters as these 3 features all had the lowest total correlations as well as low correlation values with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7329680037073145, 2.1948466714079466, 1.6361565821815707, 3.560806103766256, 1.5099574136833491, 1.273709376402949, 1.786414884476453, 3.264330658962157, 1.9324017245762282, 1.884353906738323, 1.7827839781681039, 2.7386064388550784]\n"
     ]
    }
   ],
   "source": [
    "corr = no_title.corr()\n",
    "total_corr = []\n",
    "c = 0\n",
    "for feature in corr:\n",
    "    ind = 0\n",
    "    for i in corr[feature]:\n",
    "        if c == 0:\n",
    "            total_corr.append(0)\n",
    "        total_corr[ind] += abs(i)\n",
    "        ind+=1\n",
    "    c += 1\n",
    "print(total_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acousticness</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.184256</td>\n",
       "      <td>-0.007125</td>\n",
       "      <td>-0.520882</td>\n",
       "      <td>0.069646</td>\n",
       "      <td>-0.003758</td>\n",
       "      <td>-0.066380</td>\n",
       "      <td>-0.419566</td>\n",
       "      <td>-0.036140</td>\n",
       "      <td>-0.146195</td>\n",
       "      <td>-0.104638</td>\n",
       "      <td>-0.174381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability</th>\n",
       "      <td>-0.184256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083887</td>\n",
       "      <td>-0.041506</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.013918</td>\n",
       "      <td>-0.068204</td>\n",
       "      <td>0.057201</td>\n",
       "      <td>0.232517</td>\n",
       "      <td>-0.133679</td>\n",
       "      <td>0.097874</td>\n",
       "      <td>0.273697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms</th>\n",
       "      <td>-0.007125</td>\n",
       "      <td>-0.083887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.089369</td>\n",
       "      <td>0.027760</td>\n",
       "      <td>-0.045954</td>\n",
       "      <td>0.056755</td>\n",
       "      <td>-0.090763</td>\n",
       "      <td>-0.018312</td>\n",
       "      <td>-0.004759</td>\n",
       "      <td>-0.025812</td>\n",
       "      <td>-0.185662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>-0.520882</td>\n",
       "      <td>-0.041506</td>\n",
       "      <td>-0.089369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.054364</td>\n",
       "      <td>0.032311</td>\n",
       "      <td>0.171197</td>\n",
       "      <td>0.732734</td>\n",
       "      <td>-0.099753</td>\n",
       "      <td>0.193083</td>\n",
       "      <td>0.182769</td>\n",
       "      <td>0.442839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumentalness</th>\n",
       "      <td>0.069646</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.027760</td>\n",
       "      <td>-0.054364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033556</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>-0.212182</td>\n",
       "      <td>-0.022305</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.011647</td>\n",
       "      <td>-0.066750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <td>-0.003758</td>\n",
       "      <td>0.013918</td>\n",
       "      <td>-0.045954</td>\n",
       "      <td>0.032311</td>\n",
       "      <td>0.033556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>0.008563</td>\n",
       "      <td>0.078638</td>\n",
       "      <td>-0.002376</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.038061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liveness</th>\n",
       "      <td>-0.066380</td>\n",
       "      <td>-0.068204</td>\n",
       "      <td>0.056755</td>\n",
       "      <td>0.171197</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074880</td>\n",
       "      <td>0.150872</td>\n",
       "      <td>0.068766</td>\n",
       "      <td>0.047602</td>\n",
       "      <td>0.067690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loudness</th>\n",
       "      <td>-0.419566</td>\n",
       "      <td>0.057201</td>\n",
       "      <td>-0.090763</td>\n",
       "      <td>0.732734</td>\n",
       "      <td>-0.212182</td>\n",
       "      <td>0.008563</td>\n",
       "      <td>0.074880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.106264</td>\n",
       "      <td>0.127396</td>\n",
       "      <td>0.143307</td>\n",
       "      <td>0.291474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speechiness</th>\n",
       "      <td>-0.036140</td>\n",
       "      <td>0.232517</td>\n",
       "      <td>-0.018312</td>\n",
       "      <td>-0.099753</td>\n",
       "      <td>-0.022305</td>\n",
       "      <td>0.078638</td>\n",
       "      <td>0.150872</td>\n",
       "      <td>-0.106264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.113213</td>\n",
       "      <td>0.052869</td>\n",
       "      <td>0.021518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempo</th>\n",
       "      <td>-0.146195</td>\n",
       "      <td>-0.133679</td>\n",
       "      <td>-0.004759</td>\n",
       "      <td>0.193083</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>-0.002376</td>\n",
       "      <td>0.068766</td>\n",
       "      <td>0.127396</td>\n",
       "      <td>0.113213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014236</td>\n",
       "      <td>0.078833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_signature</th>\n",
       "      <td>-0.104638</td>\n",
       "      <td>0.097874</td>\n",
       "      <td>-0.025812</td>\n",
       "      <td>0.182769</td>\n",
       "      <td>0.011647</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.047602</td>\n",
       "      <td>0.143307</td>\n",
       "      <td>0.052869</td>\n",
       "      <td>0.014236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.097703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valence</th>\n",
       "      <td>-0.174381</td>\n",
       "      <td>0.273697</td>\n",
       "      <td>-0.185662</td>\n",
       "      <td>0.442839</td>\n",
       "      <td>-0.066750</td>\n",
       "      <td>0.038061</td>\n",
       "      <td>0.067690</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>0.021518</td>\n",
       "      <td>0.078833</td>\n",
       "      <td>0.097703</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  acousticness  danceability  duration_ms    energy  \\\n",
       "acousticness          1.000000     -0.184256    -0.007125 -0.520882   \n",
       "danceability         -0.184256      1.000000    -0.083887 -0.041506   \n",
       "duration_ms          -0.007125     -0.083887     1.000000 -0.089369   \n",
       "energy               -0.520882     -0.041506    -0.089369  1.000000   \n",
       "instrumentalness      0.069646      0.008108     0.027760 -0.054364   \n",
       "key                  -0.003758      0.013918    -0.045954  0.032311   \n",
       "liveness             -0.066380     -0.068204     0.056755  0.171197   \n",
       "loudness             -0.419566      0.057201    -0.090763  0.732734   \n",
       "speechiness          -0.036140      0.232517    -0.018312 -0.099753   \n",
       "tempo                -0.146195     -0.133679    -0.004759  0.193083   \n",
       "time_signature       -0.104638      0.097874    -0.025812  0.182769   \n",
       "valence              -0.174381      0.273697    -0.185662  0.442839   \n",
       "\n",
       "                  instrumentalness       key  liveness  loudness  speechiness  \\\n",
       "acousticness              0.069646 -0.003758 -0.066380 -0.419566    -0.036140   \n",
       "danceability              0.008108  0.013918 -0.068204  0.057201     0.232517   \n",
       "duration_ms               0.027760 -0.045954  0.056755 -0.090763    -0.018312   \n",
       "energy                   -0.054364  0.032311  0.171197  0.732734    -0.099753   \n",
       "instrumentalness          1.000000  0.033556  0.001823 -0.212182    -0.022305   \n",
       "key                       0.033556  1.000000  0.012247  0.008563     0.078638   \n",
       "liveness                  0.001823  0.012247  1.000000  0.074880     0.150872   \n",
       "loudness                 -0.212182  0.008563  0.074880  1.000000    -0.106264   \n",
       "speechiness              -0.022305  0.078638  0.150872 -0.106264     1.000000   \n",
       "tempo                     0.001817 -0.002376  0.068766  0.127396     0.113213   \n",
       "time_signature            0.011647  0.004328  0.047602  0.143307     0.052869   \n",
       "valence                  -0.066750  0.038061  0.067690  0.291474     0.021518   \n",
       "\n",
       "                     tempo  time_signature   valence  \n",
       "acousticness     -0.146195       -0.104638 -0.174381  \n",
       "danceability     -0.133679        0.097874  0.273697  \n",
       "duration_ms      -0.004759       -0.025812 -0.185662  \n",
       "energy            0.193083        0.182769  0.442839  \n",
       "instrumentalness  0.001817        0.011647 -0.066750  \n",
       "key              -0.002376        0.004328  0.038061  \n",
       "liveness          0.068766        0.047602  0.067690  \n",
       "loudness          0.127396        0.143307  0.291474  \n",
       "speechiness       0.113213        0.052869  0.021518  \n",
       "tempo             1.000000        0.014236  0.078833  \n",
       "time_signature    0.014236        1.000000  0.097703  \n",
       "valence           0.078833        0.097703  1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid overfitting in our models, it is necessary to split our data into two separate sets of test and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Anaconda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Applications/Anaconda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(z_scores, data['label'])\n",
    "\n",
    "test_2 = z_scores[['danceability', 'instrumentalness', 'tempo']]\n",
    "x_train2, x_test2, y_train2, y_test2= train_test_split(test_2, data['label'])\n",
    "\n",
    "test_3 = z_scores[['key', 'instrumentalness', 'duration_ms']]\n",
    "x_train3, x_test3, y_train3, y_test3= train_test_split(test_3, data['label'])\n",
    "\n",
    "test_4 = z_scores['instrumentalness']\n",
    "test_4 = test_4.reshape(-1, 1)\n",
    "x_train4, x_test4, y_train4, y_test4= train_test_split(test_4, data['label'])\n",
    "\n",
    "test_5 = z_scores['danceability']\n",
    "test_5 = test_5.reshape(-1, 1)\n",
    "x_train5, x_test5, y_train5, y_test5 = train_test_split(test_5, data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00097579  0.08068851 -0.01852426 -0.0218908  -0.0940087   0.04737814\n",
      "   0.0872155  -0.03081238  0.12176537 -0.01088375  0.15282356 -0.01023655]] [-0.00649524]\n",
      "[[ 0.08858641 -0.17847206  0.06963795]] [-0.02325389]\n",
      "[[ 0.04964789 -0.10848833  0.0208787 ]] [0.03047382]\n",
      "[[-0.10979543]] [0.02579645]\n",
      "[[0.07496853]] [0.02213272]\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression()\n",
    "clf1.fit(x_train, y_train)\n",
    "predicted_train = clf1.predict(x_train)\n",
    "predicted_test = clf1.predict(x_test)\n",
    "print (clf1.coef_, clf1.intercept_)\n",
    "\n",
    "clf2 = LogisticRegression()\n",
    "clf2.fit(x_train2, y_train2)\n",
    "predicted_train2 = clf2.predict(x_train2)\n",
    "predicted_test2 = clf2.predict(x_test2)\n",
    "print (clf2.coef_, clf2.intercept_)\n",
    "\n",
    "clf3 = LogisticRegression()\n",
    "clf3.fit(x_train3, y_train3)\n",
    "predicted_train3 = clf3.predict(x_train3)\n",
    "predicted_test3 = clf3.predict(x_test3)\n",
    "print (clf3.coef_, clf3.intercept_)\n",
    "\n",
    "clf4 = LogisticRegression()\n",
    "clf4.fit(x_train4, y_train4)\n",
    "predicted_train4 = clf4.predict(x_train4)\n",
    "predicted_test4 = clf4.predict(x_test4)\n",
    "print (clf4.coef_, clf4.intercept_)\n",
    "\n",
    "clf5 = LogisticRegression()\n",
    "clf5.fit(x_train5, y_train5)\n",
    "predicted_train5 = clf5.predict(x_train5)\n",
    "predicted_test5 = clf5.predict(x_test5)\n",
    "#print(predicted_test5)\n",
    "print (clf5.coef_, clf5.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next need to examine and analyize predictive power of our different models.\n",
    "\n",
    "Here we see that for every set of predictors, the model is able to predict popularity with an accuracy between 51-53%, while for the test data the amount of variance that can be explained is even lower. None of these logistic regressions are very powerful predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1-rsq = 0.546020, Testing 1-rsq = 0.455224, all effects\n",
      "Training 2-rsq = 0.526119, Testing 2-rsq = 0.529851, danceability, instrumentalness, and tempo\n",
      "Training 3-rsq = 0.511194, Testing 3-rsq = 0.470149, key, instrumentalness, and duration\n",
      "Training 4-rsq = 0.504975, Testing 4-rsq = 0.477612, instrumentalness only\n",
      "Training 5-rsq = 0.541045, Testing 5-rsq = 0.514925, danceability only\n"
     ]
    }
   ],
   "source": [
    "train1_rsq = clf1.score(x_train, y_train)\n",
    "test1_rsq = clf1.score(x_test, y_test)\n",
    "print(\"Training 1-rsq = %f, Testing 1-rsq = %f, all effects\" % (train1_rsq, test1_rsq))\n",
    "    \n",
    "train2_rsq = clf2.score(x_train2, y_train2)\n",
    "test2_rsq = clf2.score(x_test2, y_test2)\n",
    "print(\"Training 2-rsq = %f, Testing 2-rsq = %f, danceability, instrumentalness, and tempo\" % (train2_rsq, test2_rsq))\n",
    "\n",
    "train3_rsq = clf3.score(x_train3, y_train3)\n",
    "test3_rsq = clf3.score(x_test3, y_test3)\n",
    "print(\"Training 3-rsq = %f, Testing 3-rsq = %f, key, instrumentalness, and duration\" % (train3_rsq, test3_rsq))\n",
    "\n",
    "train4_rsq = clf4.score(x_train4, y_train4)\n",
    "test4_rsq = clf4.score(x_test4, y_test4)\n",
    "print(\"Training 4-rsq = %f, Testing 4-rsq = %f, instrumentalness only\" % (train4_rsq, test4_rsq))\n",
    "\n",
    "train5_rsq = clf5.score(x_train5, y_train5)\n",
    "test5_rsq = clf5.score(x_test5, y_test5)\n",
    "print(\"Training 5-rsq = %f, Testing 5-rsq = %f, danceability only\" % (train5_rsq, test5_rsq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to calculate the precision and recall of our models in order to better analyize their effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditions(predicted, actual):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == actual[i]:\n",
    "            if predicted[i] == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "        else:\n",
    "            if predicted[i] == 1:\n",
    "                FP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "    return(TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(TP, FP):\n",
    "    if TP+FP != 0:\n",
    "        return(float(TP)/float(TP+FP))\n",
    "    else:\n",
    "        return(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(TP, FN):\n",
    "    if TP+FN != 0:\n",
    "        return(float(TP)/float(TP+FN))\n",
    "    else:\n",
    "        return(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 : Precision = 0.451327, Recall = 0.377778\n",
      "Test 2 : Precision = 0.543478, Recall = 0.543478\n",
      "Test 3 : Precision = 0.463158, Recall = 0.687500\n",
      "Test 4 : Precision = 0.479087, Recall = 0.976744\n",
      "Test 5 : Precision = 0.500000, Recall = 0.638462\n"
     ]
    }
   ],
   "source": [
    "y_test = list(y_test)\n",
    "TP1, TN1, FP1, FN1 = conditions(predicted_test, y_test)\n",
    "print(\"Test 1 : Precision = %f, Recall = %f\" % (precision(TP1,FP1), recall(TP1, FN1)))\n",
    "\n",
    "y_test2 = list(y_test2)\n",
    "TP2, TN2, FP2, FN2 = conditions(predicted_test2, y_test2)\n",
    "print(\"Test 2 : Precision = %f, Recall = %f\" % (precision(TP2,FP2), recall(TP2, FN2)))\n",
    "\n",
    "y_test3 = list(y_test3)\n",
    "TP3, TN3, FP3, FN3 = conditions(predicted_test3, y_test3)\n",
    "print(\"Test 3 : Precision = %f, Recall = %f\" % (precision(TP3,FP3), recall(TP3, FN3)))\n",
    "\n",
    "y_test4 = list(y_test4)\n",
    "TP4, TN4, FP4, FN4 = conditions(predicted_test4, y_test4)\n",
    "print(\"Test 4 : Precision = %f, Recall = %f\" % (precision(TP4,FP4), recall(TP4, FN4)))\n",
    "\n",
    "y_test5 = list(y_test5)\n",
    "TP5, TN5, FP5, FN5 = conditions(predicted_test5, y_test5)\n",
    "print(\"Test 5 : Precision = %f, Recall = %f\" % (precision(TP5,FP5), recall(TP5, FN5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see that the precsion of all of our models is not very high, that is that we have a similar number of true positives as false positives, while the recall of each model has a very large range. Model 4 has by far the highest recall, meaning that there were very few false negatives when using that model: i.e. songs that the model thought would not be popular but were actually popular. This model is likely due to the property that this model predicts that almost all songs will be popular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.10979542508335191 0.025796445297039776\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1d9010f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = x_test4\n",
    "y = y_test4\n",
    "#line = matplotlib.lines.Line2D(clf4.coef_, clf4.intercept_)\n",
    "plt.scatter(x, y, c='b')\n",
    "slope = clf4.coef_[0][0]\n",
    "intercept = clf4.intercept_[0]\n",
    "print(slope, intercept)\n",
    "\n",
    "# Create a list of values in the best fit line\n",
    "abline_values = [slope * i + intercept for i in x]\n",
    "# Plot the best fit line over the actual values\n",
    "plt.plot(x, abline_values, 'b')\n",
    "plt.title(slope)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
