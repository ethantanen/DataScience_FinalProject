{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network \n",
    "\n",
    "The linear regression yielded poor results, so we thought a more complex regression might lend towards a better analysis. For this we decided to build a neural network using Tensorflow. We chose a feedforward neural network due to its ability to model non linear functions.\n",
    "\n",
    "We begin by importing the Tensorflow module, which provides a framework for, what seems like, every type of modeling technique. Take note that 'tf' is the industry standard alias for tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we read in the balanced song features dataset, which includes data on every song that has appeared on the Billboard Hot 100 since 2010. Intially the dataset was split such that 70% of the music was unpopular and 30% popular. After completing the training the network had an outstanding 70% accuracy! Under further investigation, we realized the networks was simply assigning everything an unpopular label. Do remedy this we modified our dataset such that there was a 50-50 split between popular and unpopular songs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21400</td>\n",
       "      <td>0.666</td>\n",
       "      <td>178242</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>-5.743</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>100.014</td>\n",
       "      <td>4</td>\n",
       "      <td>0.178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.807</td>\n",
       "      <td>183750</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>-3.282</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>127.973</td>\n",
       "      <td>4</td>\n",
       "      <td>0.651</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00162</td>\n",
       "      <td>0.791</td>\n",
       "      <td>279507</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>-6.149</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>128.017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.76300</td>\n",
       "      <td>0.707</td>\n",
       "      <td>275227</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>-3.979</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>89.094</td>\n",
       "      <td>4</td>\n",
       "      <td>0.501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.57000</td>\n",
       "      <td>0.629</td>\n",
       "      <td>250173</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>-7.733</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>100.015</td>\n",
       "      <td>4</td>\n",
       "      <td>0.386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n",
       "0       0.21400         0.666       178242   0.677          0.000000    2   \n",
       "1       0.01340         0.807       183750   0.916          0.000012    0   \n",
       "2       0.00162         0.791       279507   0.615          0.000065    6   \n",
       "3       0.76300         0.707       275227   0.709          0.000000   11   \n",
       "4       0.57000         0.629       250173   0.572          0.000000    5   \n",
       "\n",
       "   liveness  loudness  speechiness    tempo  time_signature  valence  label  \n",
       "0    0.0979    -5.743       0.0326  100.014               4    0.178      1  \n",
       "1    0.0787    -3.282       0.2260  127.973               4    0.651      1  \n",
       "2    0.0812    -6.149       0.0667  128.017               4    0.393      1  \n",
       "3    0.2740    -3.979       0.3400   89.094               4    0.501      1  \n",
       "4    0.1920    -7.733       0.0387  100.015               4    0.386      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in File\n",
    "data = pd.read_csv(\"balanced_pop_unpop_features.csv\")\n",
    "\n",
    "#Remove track name column\n",
    "del data[\"Unnamed: 0\"]\n",
    "\n",
    "#Quick look at the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tensorflow software below automatically shuffles the data, but just to be sure the following line of code mixes up the rows of the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0.25400</td>\n",
       "      <td>0.397</td>\n",
       "      <td>354320</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2680</td>\n",
       "      <td>-9.910</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>142.913</td>\n",
       "      <td>4</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.00877</td>\n",
       "      <td>0.583</td>\n",
       "      <td>172893</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>-4.087</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>89.993</td>\n",
       "      <td>4</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>0.04330</td>\n",
       "      <td>0.836</td>\n",
       "      <td>218173</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0773</td>\n",
       "      <td>-5.660</td>\n",
       "      <td>0.0851</td>\n",
       "      <td>97.036</td>\n",
       "      <td>4</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00256</td>\n",
       "      <td>0.618</td>\n",
       "      <td>196693</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>-5.738</td>\n",
       "      <td>0.3180</td>\n",
       "      <td>190.050</td>\n",
       "      <td>4</td>\n",
       "      <td>0.603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.15800</td>\n",
       "      <td>0.536</td>\n",
       "      <td>286267</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3680</td>\n",
       "      <td>-3.002</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>185.967</td>\n",
       "      <td>4</td>\n",
       "      <td>0.779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n",
       "683        0.25400         0.397       354320   0.396               0.0    3   \n",
       "888        0.00877         0.583       172893   0.791               0.0   11   \n",
       "1052       0.04330         0.836       218173   0.552               0.0    7   \n",
       "10         0.00256         0.618       196693   0.717               0.0    7   \n",
       "440        0.15800         0.536       286267   0.946               0.0    5   \n",
       "\n",
       "      liveness  loudness  speechiness    tempo  time_signature  valence  label  \n",
       "683     0.2680    -9.910       0.0500  142.913               4    0.227      0  \n",
       "888     0.0451    -4.087       0.0318   89.993               4    0.878      0  \n",
       "1052    0.0773    -5.660       0.0851   97.036               4    0.525      0  \n",
       "10      0.6250    -5.738       0.3180  190.050               4    0.603      1  \n",
       "440     0.3680    -3.002       0.3600  185.967               4    0.779      1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shuffle dataset\n",
    "for i in range(10): data = data.sample(frac=1)\n",
    "    \n",
    "#Quick look at the shuffled data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model \n",
    "\n",
    "To model the data, the data is split 70-30, where 70% of the data is used to train the model and 30% of the data is used to test the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 13) (322, 13)\n"
     ]
    }
   ],
   "source": [
    "#About a 70-30 split between training and testing \n",
    "train = data.iloc[:750]\n",
    "test = data.iloc[750:]\n",
    "\n",
    "#Quick look at shape of the two sets\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the training and test sets are split into sets of features and labels. Immedietly following, the sets are normalized using a Z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0.418731</td>\n",
       "      <td>-1.786499</td>\n",
       "      <td>3.170214</td>\n",
       "      <td>-1.665288</td>\n",
       "      <td>-0.113488</td>\n",
       "      <td>-0.649060</td>\n",
       "      <td>0.681180</td>\n",
       "      <td>-1.580271</td>\n",
       "      <td>-0.480727</td>\n",
       "      <td>0.776980</td>\n",
       "      <td>0.099303</td>\n",
       "      <td>-1.269302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>-0.777201</td>\n",
       "      <td>-0.447223</td>\n",
       "      <td>-1.218397</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>-0.113488</td>\n",
       "      <td>1.513272</td>\n",
       "      <td>-0.970816</td>\n",
       "      <td>0.774776</td>\n",
       "      <td>-0.665296</td>\n",
       "      <td>-1.069459</td>\n",
       "      <td>0.099303</td>\n",
       "      <td>1.629052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>-0.608806</td>\n",
       "      <td>1.374482</td>\n",
       "      <td>-0.123101</td>\n",
       "      <td>-0.750508</td>\n",
       "      <td>-0.113488</td>\n",
       "      <td>0.432106</td>\n",
       "      <td>-0.732170</td>\n",
       "      <td>0.138594</td>\n",
       "      <td>-0.124773</td>\n",
       "      <td>-0.823721</td>\n",
       "      <td>0.099303</td>\n",
       "      <td>0.057441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.807486</td>\n",
       "      <td>-0.195208</td>\n",
       "      <td>-0.642689</td>\n",
       "      <td>0.217047</td>\n",
       "      <td>-0.113488</td>\n",
       "      <td>0.432106</td>\n",
       "      <td>3.327041</td>\n",
       "      <td>0.107047</td>\n",
       "      <td>2.237100</td>\n",
       "      <td>2.421644</td>\n",
       "      <td>0.099303</td>\n",
       "      <td>0.404709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.049440</td>\n",
       "      <td>-0.785642</td>\n",
       "      <td>1.524052</td>\n",
       "      <td>1.559896</td>\n",
       "      <td>-0.113488</td>\n",
       "      <td>-0.108477</td>\n",
       "      <td>1.422317</td>\n",
       "      <td>1.213592</td>\n",
       "      <td>2.663028</td>\n",
       "      <td>2.279183</td>\n",
       "      <td>0.099303</td>\n",
       "      <td>1.188289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acousticness  danceability  duration_ms    energy  instrumentalness  \\\n",
       "683       0.418731     -1.786499     3.170214 -1.665288         -0.113488   \n",
       "888      -0.777201     -0.447223    -1.218397  0.650980         -0.113488   \n",
       "1052     -0.608806      1.374482    -0.123101 -0.750508         -0.113488   \n",
       "10       -0.807486     -0.195208    -0.642689  0.217047         -0.113488   \n",
       "440      -0.049440     -0.785642     1.524052  1.559896         -0.113488   \n",
       "\n",
       "           key  liveness  loudness  speechiness     tempo  time_signature  \\\n",
       "683  -0.649060  0.681180 -1.580271    -0.480727  0.776980        0.099303   \n",
       "888   1.513272 -0.970816  0.774776    -0.665296 -1.069459        0.099303   \n",
       "1052  0.432106 -0.732170  0.138594    -0.124773 -0.823721        0.099303   \n",
       "10    0.432106  3.327041  0.107047     2.237100  2.421644        0.099303   \n",
       "440  -0.108477  1.422317  1.213592     2.663028  2.279183        0.099303   \n",
       "\n",
       "       valence  \n",
       "683  -1.269302  \n",
       "888   1.629052  \n",
       "1052  0.057441  \n",
       "10    0.404709  \n",
       "440   1.188289  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split entries in train_x: features and train_y: labels\n",
    "train_x = train.iloc[:,:12]\n",
    "train_y = train.iloc[:,12:].astype(int)\n",
    "\n",
    "test_x = test.iloc[:,:12]\n",
    "test_y = test.iloc[:,12:].astype(int)\n",
    "\n",
    "#Take Z-score\n",
    "train_x = (train_x-train_x.mean())/(train_x.std())\n",
    "test_x = (test_x-test_x.mean())/(test_x.std())\n",
    "\n",
    "#Quick look at training set\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow requires that a list of column features be provided in order to specify the type of input. The neural network is capable of using other feature types other than numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_NumericColumn(key='acousticness', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None) \n",
      "\n",
      "_NumericColumn(key='danceability', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create feature column for net \n",
    "feature_columns = []\n",
    "for i in train_x.columns:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key=i))\n",
    "\n",
    "#Little preview of the numeric_column object\n",
    "for i in feature_columns[:2]:\n",
    "    print(i,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is used to create the neural network. We decided to use a single hidden layer with 5 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './modeldata', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 4, '_session_config': None, '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1829376d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "#Make estimator/ Model\n",
    "\n",
    "my_checkpointing_config = tf.estimator.RunConfig(\n",
    "    save_checkpoints_secs = 4,  # Save checkpoints every 20 minutes.\n",
    "    keep_checkpoint_max = 10,       # Retain the 10 most recent checkpoints.\n",
    ")\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns\n",
    "                                        , hidden_units=[5],\n",
    "                                        n_classes=2,model_dir=\"./modeldata\",\n",
    "                                       config=my_checkpointing_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used to prepare the data for input to the neural network. It is covered in depth in the Tensorflow documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the network is training using the entirety of the training set. The Batch size is 500 and the number of steps or epochs is 1500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./modeldata/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into ./modeldata/model.ckpt.\n",
      "INFO:tensorflow:loss = 199.815, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 215.234\n",
      "INFO:tensorflow:loss = 197.24623, step = 1101 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.423\n",
      "INFO:tensorflow:loss = 196.13849, step = 1201 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.036\n",
      "INFO:tensorflow:loss = 189.52202, step = 1301 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.318\n",
      "INFO:tensorflow:loss = 196.53983, step = 1401 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.615\n",
      "INFO:tensorflow:loss = 196.28888, step = 1501 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.557\n",
      "INFO:tensorflow:loss = 198.82819, step = 1601 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.001\n",
      "INFO:tensorflow:loss = 190.923, step = 1701 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.531\n",
      "INFO:tensorflow:loss = 198.60524, step = 1801 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.813\n",
      "INFO:tensorflow:loss = 186.60143, step = 1901 (0.368 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./modeldata/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 189.39622.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1829376c88>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda:train_input_fn(train_x, train_y,300),\n",
    "    steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the network is trained it is time to test it with the testing set. The following function prepares the testing set for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
    "    features=dict(features)\n",
    "    if labels is None:\n",
    "        # No labels, use only features.\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels)\n",
    "\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "    # Batch the examples\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code runs the testing evaluate function on the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-14-21:19:22\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./modeldata/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-14-21:19:23\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.5124224, accuracy_baseline = 0.51863354, auc = 0.5245123, auc_precision_recall = 0.5282171, average_loss = 0.7214673, global_step = 2000, label/mean = 0.48136646, loss = 232.31247, precision = 0.49375, prediction/mean = 0.49740848, recall = 0.5096774\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(test_x, test_y, 3000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results of the evaluation more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5124224,\n",
       " 'accuracy_baseline': 0.51863354,\n",
       " 'auc': 0.5245123,\n",
       " 'auc_precision_recall': 0.5282171,\n",
       " 'average_loss': 0.7214673,\n",
       " 'global_step': 2000,\n",
       " 'label/mean': 0.48136646,\n",
       " 'loss': 232.31247,\n",
       " 'precision': 0.49375,\n",
       " 'prediction/mean': 0.49740848,\n",
       " 'recall': 0.5096774}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A print out of the prediction and exprected results can be found in the ANN Tests document located in the Model folder as well as a series of test done with other features and varying network shapes. \n",
    "\n",
    "From the evaluator it's clear that the neural network does a pretty bad job of modeling the data. We believe that to predict whether a song will be popular or not requires atleast some data on the cultural climate at the time. After reading a series of documents written by people conducting the same test, they also agree that analyzing a song's features is insufficient for producing meaningfull predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-0864cd8b4305>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./modeldata/graph.pbtxt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshow_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'show_graph' is not defined"
     ]
    }
   ],
   "source": [
    "gdef = tf.GraphDef()\n",
    "from google.protobuf import text_format\n",
    "text_format.Merge(open(\"./modeldata/graph.pbtxt\").read(), gdef)\n",
    "show_graph(gdef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-6a121cb108a2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-6a121cb108a2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    docker pull lspvic/tensorboard-notebook\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
